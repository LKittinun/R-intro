[
  {
    "objectID": "posts/missed_cleavage/index.html",
    "href": "posts/missed_cleavage/index.html",
    "title": "Missed cleavage",
    "section": "",
    "text": "In the bottom-up proteomic experiment, proteins are enzymatically digested into peptides prior to mass spectrometry analysis. However, due to the complex structures of proteins, certain protein sites may be partially or completely inaccessible to the enzymatic cleavage. This situation eventually leads to missed cleavages—where peptides are longer than expected due to uncleavage at intended sites. Too many missed cleavages can complicate peptide identification and quantification in downstream analysis."
  },
  {
    "objectID": "posts/missed_cleavage/index.html#how-is-missed-cleavage-calculated",
    "href": "posts/missed_cleavage/index.html#how-is-missed-cleavage-calculated",
    "title": "Missed cleavage",
    "section": "How is missed cleavage calculated?",
    "text": "How is missed cleavage calculated?\nTo identify spectra generated from the mass spectrometry, most software we used relies on a protein sequence database, typically in FASTA format, as a reference. Consequently, the software performs in silico digestion on FASTA to generate a theoretical list of peptides to map the spectra against. Consider human albumin protein as an example.\n\nalbu_human &lt;- paste(readLines(\"data/albu_human.fasta\")[-1], collapse = \"\")\nalbu_human\n\n[1] \"MKWVTFISLLFLFSSAYSRGVFRRDAHKSEVAHRFKDLGEENFKALVLIAFAQYLQQCPFEDHVKLVNEVTEFAKTCVADESAENCDKSLHTLFGDKLCTVATLRETYGEMADCCAKQEPERNECFLQHKDDNPNLPRLVRPEVDVMCTAFHDNEETFLKKYLYEIARRHPYFYAPELLFFAKRYKAAFTECCQAADKAACLLPKLDELRDEGKASSAKQRLKCASLQKFGERAFKAWAVARLSQRFPKAEFAEVSKLVTDLTKVHTECCHGDLLECADDRADLAKYICENQDSISSKLKECCEKPLLEKSHCIAEVENDEMPADLPSLAADFVESKDVCKNYAEAKDVFLGMFLYEYARRHPDYSVVLLLRLAKTYETTLEKCCAAADPHECYAKVFDEFKPLVEEPQNLIKQNCELFEQLGEYKFQNALLVRYTKKVPQVSTPTLVEVSRNLGKVGSKCCKHPEAKRMPCAEDYLSVVLNQLCVLHEKTPVSDRVTKCCTESLVNRRPCFSALEVDETYVPKEFNAETFTFHADICTLSEKERQIKKQTALVELVKHKPKATKEQLKAVMDDFAAFVEKCCKADDKETCFAEEGKKLVAASQAALGL\"\n\n\nTheoretically, we know that trypsin can digest proteins at Lysine (K) and Arginine (R) sites, where it is not followed by Proline (P) or KR/P. So, ideally, albumin should be digested into peptides based on this rule.\n\ntrypsin_digest &lt;- function(seq){\n  if (!is.character(seq) || nchar(seq) &lt;2) stop(\"Input must be &gt;2 characters string\")\n  unlist(stringi::stri_split_regex(seq, pattern = \"(?&lt;=(K(?!P)|R(?!P)))\"))\n}\n\nalbu_pep &lt;- trypsin_digest(albu_human)\n\n## Normally the softwares consider at least 5 amino acids to be valid peptides\n\nalbu_pep[nchar(albu_pep)&gt;=5]\n\n [1] \"WVTFISLLFLFSSAYSR\"           \"SEVAHR\"                     \n [3] \"DLGEENFK\"                    \"ALVLIAFAQYLQQCPFEDHVK\"      \n [5] \"LVNEVTEFAK\"                  \"TCVADESAENCDK\"              \n [7] \"SLHTLFGDK\"                   \"LCTVATLR\"                   \n [9] \"ETYGEMADCCAK\"                \"QEPER\"                      \n[11] \"NECFLQHK\"                    \"DDNPNLPR\"                   \n[13] \"LVRPEVDVMCTAFHDNEETFLK\"      \"YLYEIAR\"                    \n[15] \"HPYFYAPELLFFAK\"              \"AAFTECCQAADK\"               \n[17] \"AACLLPK\"                     \"LDELR\"                      \n[19] \"ASSAK\"                       \"CASLQK\"                     \n[21] \"AWAVAR\"                      \"AEFAEVSK\"                   \n[23] \"LVTDLTK\"                     \"VHTECCHGDLLECADDR\"          \n[25] \"ADLAK\"                       \"YICENQDSISSK\"               \n[27] \"ECCEKPLLEK\"                  \"SHCIAEVENDEMPADLPSLAADFVESK\"\n[29] \"NYAEAK\"                      \"DVFLGMFLYEYAR\"              \n[31] \"HPDYSVVLLLR\"                 \"TYETTLEK\"                   \n[33] \"CCAAADPHECYAK\"               \"VFDEFKPLVEEPQNLIK\"          \n[35] \"QNCELFEQLGEYK\"               \"FQNALLVR\"                   \n[37] \"VPQVSTPTLVEVSR\"              \"HPEAK\"                      \n[39] \"MPCAEDYLSVVLNQLCVLHEK\"       \"TPVSDR\"                     \n[41] \"CCTESLVNR\"                   \"RPCFSALEVDETYVPK\"           \n[43] \"EFNAETFTFHADICTLSEK\"         \"QTALVELVK\"                  \n[45] \"AVMDDFAAFVEK\"                \"ETCFAEEGK\"                  \n[47] \"LVAASQAALGL\"                \n\n\nThis generates a list of theoretical peptides that are digested by trypsin, which is further used to generate theoretical spectra to match against our experiment. So if the real cleavage results longer sequence than these, it means that there was incomplete digestion occurred. Suppose we digest real albumin and get some peptides.\n\npeptides &lt;- c(\"ACLLPKLDELRDEGKASSAKQR\",\n              \"KDVCKNYAEAKDVFLGMFLYEYARR\",\n              \"YICENQDSISSK\",\n              \"FGERAFKAWAVAR\",\n              \"VFDEFKPLVEEPQNLIK\")\n\nWe want to know if our digestion experiment results in missed cleavage, so we check for non-C-terminal KR/P missed cleavage.\n\ncount.missed.cleavage &lt;- function(peptide) {\n  if (!is.character(peptide) || nchar(peptide) &lt;2) stop(\"Input must be &gt;2 characters string\")\n  peptide &lt;- toupper(peptide)\n  matches &lt;- unlist(gregexpr(\"(?=(K(?!P)|R(?!P)))\", peptide, perl = TRUE))\n  matches &lt;- matches[matches &lt; nchar(peptide)]\n  length(matches)\n}\n\ndata.frame(no.cleavage = sapply(peptides, count.missed.cleavage))\n\n                          no.cleavage\nACLLPKLDELRDEGKASSAKQR              4\nKDVCKNYAEAKDVFLGMFLYEYARR           4\nYICENQDSISSK                        0\nFGERAFKAWAVAR                       2\nVFDEFKPLVEEPQNLIK                   0\n\n\nThis way, we can identify the number of cleavages present in each peptide. In the real situation, our bottom-up proteomic experiment often allows only 0-1 missed cleavage theoretical peptides in the search space for identification (so the result will only contain peptides with missed cleavage &lt;2), since missed cleavage &gt;1 results in an inconsistent peptide pattern and thus a larger search space and poor quantification result. There was an exception in some samples, e.g., plasma, which was expected to have a high missed cleavage count due to nonspecific cleavage from plasma enzymes. In this case, we might increase the missed cleavage threshold to 2."
  },
  {
    "objectID": "posts/missed_cleavage/index.html#how-to-reduce-missed-cleavage",
    "href": "posts/missed_cleavage/index.html#how-to-reduce-missed-cleavage",
    "title": "Missed cleavage",
    "section": "How to reduce missed cleavage?",
    "text": "How to reduce missed cleavage?\nThe principle of digestion improvement is to prepare proteins to be in a condition that is suitable for digestion, or improve digestion efficiency.\n\nUse the precipitation method to obtain purer proteins.\nReduce non-specific digestion from other enzymes (since we are only interested in particular enzymatic digestion, e.g., trypsin). This can be done by heat or by adding protease inhibitors.\nReduce and alkylate proteins.\nUse a higher enzyme-to-protein ratio.\nUse multiple enzymes. Most commonly, we use Lys-C in conjunction with trypsin, since Lys-C specifically cleaves C-terminal K. Our experience found that adding Lys-C results in 5-10% cleavage efficiency.\nUse a suitable time and temperature for specific enzymes. Too short will cause missed cleavage, but too long will cause autolysis and excessive digestion."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Pete’s proteomics blog",
    "section": "",
    "text": "Disclaimer: The content shared here reflects only my research and perspectives. It is not intended to serve as an official source or formal reference.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData-dependent acquisition vs. Data-independent acquisition\n\n\n\n\n\n\nInstrument\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\nJun 25, 2025\n\n\nLeetanaporn K\n\n\n\n\n\n\n\n\n\n\n\n\nMissed cleavage\n\n\n\n\n\n\nSample preparation\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\nJun 16, 2025\n\n\nLeetanaporn K\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/DDA_vs_DIA/index.html",
    "href": "posts/DDA_vs_DIA/index.html",
    "title": "Data-dependent acquisition vs. Data-independent acquisition",
    "section": "",
    "text": "If you have ever worked with untargeted proteomic results, you would likely encounter the terms data-dependent acquisition (DDA) and data-independent acquisition (DIA). Although these two acquisition schemes finally produced (generally) two-dimensional data matrices of peptides (or proteins) and intensities, they relied on fundamentally distinct mechanisms for acquiring the data. To understand how different these two approaches are, we first have to understand the fundamentals of how mass spectrometry captures and analyzes peptide signals."
  },
  {
    "objectID": "posts/DDA_vs_DIA/index.html#mass-spectrometry-data-acquisition",
    "href": "posts/DDA_vs_DIA/index.html#mass-spectrometry-data-acquisition",
    "title": "Data-dependent acquisition vs. Data-independent acquisition",
    "section": "Mass spectrometry data acquisition",
    "text": "Mass spectrometry data acquisition\nAfter peptides are injected into the mass spectrometry and ionized by the ion source, the resulting ion travels to the mass analyzers. The function of mass analyzers is to separate ionized peptides based on their m/z. For those who are confused about what m/z is, think of it this way: mass analyzers use magnetic or electric fields to separate ions, but they cannot directly measure peptide mass. Instead, they rely on the ion’s mass-to-charge ratio (m/z), where the charge helps distinguish between ions. For instance, a peptide with a mass of 1200 and a 2+ charge will appear as 600 m/z in the analyzer.\nIn untargeted proteomic analysis, commonly used mass analyzers usually involve two (or even three) mass analyzers with different functions, with collision chamber for further ion fragmentation. This setup is known as tandem mass spectrometry (MS/MS).\n\n\n\n\n\nflowchart LR\n  A[Ion Source] --- B(Mass Analyzer 1)\n  B --- C[Collision Chamber]\n  C --- D(Mass Analyzer 2)\n  D --- E[Detector]\n\n\n\n\n\n\nIn general, mass analyzer in MS/MS setup include:\n\nQuadrupole: This mass analyzer functions as the first m/z (mass-to-charge) filter, so we can define the range of the m/z that interests us most.\nTime-of-flight or Orbitrap: These are high-resolution mass analyzers. Although they have different principles of mass separation, they both share the same goal: to distinguish even minuscule m/z differences between ions with very high precision.\n\nSo, basically, data acquisition of peptide ions starts with a quadrupole to filter the m/z that we are interested in. In the case of peptides, these numbers usually range around 400-1800. Then, the filter ions are passed into the high-resolution mass analyzer, which separates the ions in finer detail. Thereafter, all separated ion data are recorded by the detector, which is then processed into the spectrum we see in the software.\n\n\n\n\n\nflowchart LR\n  A[Ion Source] --&gt; B(Quadrupole)\n  B --- C[Collision Chamber]\n  C --- D(Time-of-flight/Orbitrap)\n  D --&gt; E[Detector]\n  B -.-&gt; D\n\nlinkStyle 0,3,4 stroke:darkred,stroke-width:2px  \n\n\n\n\n\n\nWhat I recently described is basically MS1 acquisition (or full scan/precursor scan). Note that collision chamber is not used here since there is no fragmentation occurs; it will be involved in MS2."
  },
  {
    "objectID": "posts/DDA_vs_DIA/index.html#then-what-about-ms2",
    "href": "posts/DDA_vs_DIA/index.html#then-what-about-ms2",
    "title": "Data-dependent acquisition vs. Data-independent acquisition",
    "section": "Then what about MS2?",
    "text": "Then what about MS2?\nWell, what we obtain from MS1 is a list of m/z values of all ions present at the moment. This is called peptide fingerprints. However, this data is not enough to figure out what these peptides really are, because some peptides have the same m/z even though their sequences are different. This is why we need MS2, where we break down these ions into smaller pieces via a collision chamber to analyze their patterns further.\n\n\n\n\n\nflowchart LR\n  A[Ion Source] --&gt; B(Quadrupole)\n  B --&gt; C[\"Collision Chamber (Fragmentation)\"]\n  C --&gt; D(Time-of-flight/Orbitrap)\n  D --&gt; E[Detector]\n\nlinkStyle 0,1,2,3 stroke:darkred,stroke-width:2px  \n\n\n\n\n\n\nThis is where the difference between DDA and DIA acquisition kicks in, because these two approaches have clearly distinct patterns to obtain MS2.\n\nData-dependent acquisition\nThere is a specific time window during which peptides with the same or similar properties elute together as a single peak. This allows mass spectrometry to collect multiple data points as the peak elutes. Mass spectrometry collects multiple rounds of data in one peak. Each round of the scans consists of one MS1 and multiple MS2 scans; this is called a cycle, and the time it takes to complete a cycle is called cycle time.\n\n\n\n\n\n1 cycle = time to complete all defined scan = MS1 to MS1\n\n\n\n\nFor DDA, in one cycle, the top N most intense data in MS1 (aka precursor ions) will be further fragmented into MS2 (daughter ions). Take a look at the picture below, the 5 most intense spectra in this MS1 are then individually fragmented and analyzed in separate MS2 scans sequentially (not simultaneously!), resulting in 5 following MS2 (red triangle in the above picture). This is why it is called “data-dependent”–it depends on the MS1 data. It is a classic data acquisition scheme that has been used since the beginning of the shotgun proteomic era.\n\n\n\n\n\nNote: the shade I made is larger than the actual experiment for visualization. In the real experiment, the quadrupole is very efficient and can isolate within +/- 1-2 m/z, or even lower in modern mass spectrometry.\n\n\n\n\nWell, this is a solid method for identifying peptides. Still, there’s a catch: the fragmentation tends to favor more abundant precursor ions. In other words, more abundant peptides are more likely to get selected for fragmentation, while less abundant peptides may get overlooked. Therefore, when you see quite a lot of missing data in your final data matrix, there is a good chance it was acquired by DDA. To compensate for this bias, most instruments use a feature called dynamic exclusion that prevents repeated fragmentation of the same precursors within a short time window. But that’s getting a little bit too technical–we’ll talk about it in a future post.\n\n\nData-independent acquisition\nAs I stated, DDA has a limitation that it is bias towards more abundant precursors. So why don’t we just fragment it all? Well, this is exactly the concept behind DIA. It works by sequentially fragmenting all ions within the defined mass windows.\n\n\n\n\n\nAll ions within predefined m/z windows are selected for fragmentation. Pink shaded regions represent isolation windows, dashed lines indicate window boundaries.\n\n\n\n\nAs you can see in the figure, for this MS1, the next 12 windows will be sequentially fragmented in MS2. In this way, all ions–more or less–get a chance to be fragmented without bias. This makes the fragmentation pattern much more predictable, resulting in more robust, reproducible spectra generation across the run. Accordingly, there will be a lot less missing data events than DDA, especially in low-abundant peptides. There is a lot of variation in window fragmentation patterns, such as staggered windows and variable-width windows that are designed to optimize coverage and improve sensitivity, depending on the instruments.\nTerrific! So, should we entirely abandon DDA and move to DDA? Not exactly, for now. While it results in much more reproducible spectra, the spectra themselves are much more complicated. This is because there are multiple precursors fragmented together within one window, leading to chimeric spectra. DDA typically isolates and fragments individual precursors within narrow windows, making chimeric events much less likely. Therefore, identifying peptides from these spectra often requires library–a pre-built reference of known peptide fragmentation pattern–to serve as a spectrum blueprint to match spectra with overlapping fragmented ions.\nLuckily, the bioinformatics tools for DIA are rapidly evolving, making it very feasible to analyze these spectra with ease. Most modern proteomics tools now support analyzing DIA without requiring much effort from the users. Some tools can even do it with library-free settings, such as DIA-NN, MaxQuant, Spectronaut, MSFragger, and many more. Note that proper methods for false discovery estimation in DIA are still in debate. Still, in a general label-free workflow, DIA is now a highly accessible and powerful option at the moment.\n\n\nSo, DDA still has the place?\nAbsolutely. While currently DIA is the go-to for general label-free workflow, certain methods still prefer DDA, such as:\n\nPost-translational modification analysis, DDA provides much cleaner MS2 spectra, which are critical for confident PTM modification site localization. (Though DIA is rapidly catching up in this area.)\nLabel-based proteomics, especially with tandem mass tag.\nBuilding a tailored spectral library for some projects.\nPeptidomics, your regular computer could explode due to a very large search space.\nDe novo sequencing, since interpreting chimeric spectra without prior knowledge is still highly challenging."
  },
  {
    "objectID": "posts/DDA_vs_DIA/index.html#conclusion",
    "href": "posts/DDA_vs_DIA/index.html#conclusion",
    "title": "Data-dependent acquisition vs. Data-independent acquisition",
    "section": "Conclusion",
    "text": "Conclusion\nSo, while DIA is rapidly evolving and can replace some DDA workflows, DDA still has a place, especially when you need to do experiments that require much cleaner spectra, such as PTM or de novo sequencing. Choosing the right approach depends on your specific research questions and analytic goals. But who knows what it will be in the future? With continuous improvements in mass spectrometry hardware and software, the line between DDA and DIA will only grow more flexible."
  }
]